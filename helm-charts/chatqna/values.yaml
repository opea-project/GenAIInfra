# Copyright (C) 2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

# Default values for chatqna.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: opea/chatqna
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: "latest"

port: 8888
service:
  type: ClusterIP
  port: 8888

securityContext:
  readOnlyRootFilesystem: true
  allowPrivilegeEscalation: false
  runAsNonRoot: true
  runAsUser: 1000
  capabilities:
    drop:
    - ALL
  seccompProfile:
    type: RuntimeDefault

nodeSelector: {}

tolerations: []

affinity: {}

# Enabling HorizontalPodAutoscaler (HPA) will:
# - Overwrite named PrometheusAdapter configMap with ChatQnA specific custom metric queries
#   for embedding, reranking, tgi services
# Note: default configMap in upstream:
#  - https://github.com/kubernetes-sigs/prometheus-adapter/blob/master/deploy/manifests/config-map.yaml
horizontalPodAutoscaler:
  enabled: false

# Override values in specific subcharts

# Enabling "horizontalPodAutoscaler" for any of the subcharts requires enabling it also above!
tgi:
  LLM_MODEL_ID: Intel/neural-chat-7b-v3-3
  horizontalPodAutoscaler:
    maxReplicas: 4
    enabled: false
teirerank:
  horizontalPodAutoscaler:
    maxReplicas: 3
    enabled: false
tei:
  horizontalPodAutoscaler:
    maxReplicas: 2
    enabled: false

# disable guardrails-usvc by default
# See guardrails-values.yaml for guardrail related options
guardrails-usvc:
  enabled: false

# If you would like to switch to traditional UI image
# Uncomment the following lines
# chatqna-ui:
#   image:
#     repository: "opea/chatqna-ui"
#     tag: "latest"
#   containerPort: "5173"

global:
  http_proxy: ""
  https_proxy: ""
  no_proxy: ""
  HUGGINGFACEHUB_API_TOKEN: "insert-your-huggingface-token-here"
  # set modelUseHostPath or modelUsePVC to use model cache.
  modelUseHostPath: ""
  # modelUseHostPath: /mnt/opea-models
  # modelUsePVC: model-volume
