{{- if and .Values.global.monitoring .Values.autoscaling.enabled }}
# Copyright (C) 2024-2025 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

apiVersion: v1
kind: ConfigMap
metadata:
  # easy to find for the manual step required to install this for Prometheus-adapter
  namespace: default
  name: {{ include "chatqna.fullname" . }}-custom-metrics
  labels:
    app.kubernetes.io/name: prometheus-adapter
data:
  config.yaml: |
    rules:
    # check metric with:
    # kubectl get --raw /apis/custom.metrics.k8s.io/v1beta1/namespaces/default/service/*/<metric> | jq
    #
    {{- if and .Values.vllm.enabled .Values.vllm.autoscaling.enabled }}
    - seriesQuery: '{__name__="vllm:num_requests_waiting",service="{{ include "vllm.fullname" .Subcharts.vllm }}"}'
      # Sum of requests waiting to be processed in pods
      metricsQuery: 'sum by (<<.GroupBy>>)(<<.Series>>{<<.LabelMatchers>>})'
      name:
        matches: ^vllm:num_requests_waiting
        as: "{{ include "vllm.metricPrefix" .Subcharts.vllm }}_queue_size_sum"
      resources:
        # HPA needs both namespace + suitable object resource for its query paths:
        # /apis/custom.metrics.k8s.io/v1beta1/namespaces/default/service/*/<metric>
        # (pod is not suitable object type for matching as each instance has different name)
        overrides:
          namespace: {resource: "namespace"}
          service:   {resource: "service"}
    {{- end }}
    {{- if and .Values.tgi.enabled .Values.tgi.autoscaling.enabled }}
    - seriesQuery: '{__name__="tgi_queue_size",service="{{ include "tgi.fullname" .Subcharts.tgi }}"}'
      # TGI instances queue_size sum
      # - GroupBy/LabelMatches provide labels from resources section
      metricsQuery: 'sum by (<<.GroupBy>>)(<<.Series>>{<<.LabelMatchers>>})'
      name:
        matches: ^tgi_queue_size
        as: "{{ include "tgi.metricPrefix" .Subcharts.tgi }}_queue_size_sum"
      resources:
        overrides:
          namespace: {resource: "namespace"}
          service:   {resource: "service"}
    {{- end }}
    {{- if and .Values.teirerank.enabled .Values.teirerank.autoscaling.enabled }}
    - seriesQuery: '{__name__="te_queue_size",service="{{ include "teirerank.fullname" .Subcharts.teirerank }}"}'
      # TEI instances queue_size sum
      metricsQuery: 'sum by (<<.GroupBy>>)(<<.Series>>{<<.LabelMatchers>>})'
      name:
        matches: ^te_queue_size
        as: "{{ include "teirerank.metricPrefix" .Subcharts.teirerank }}_queue_size_sum"
      resources:
        overrides:
          namespace: {resource: "namespace"}
          service:   {resource: "service"}
    {{- end }}
    {{- if .Values.tei.autoscaling.enabled }}
    - seriesQuery: '{__name__="te_queue_size",service="{{ include "tei.fullname" .Subcharts.tei }}"}'
      # TEI instances queue_size sum
      metricsQuery: 'sum by (<<.GroupBy>>)(<<.Series>>{<<.LabelMatchers>>})'
      name:
        matches: ^te_queue_size
        as: "{{ include "tei.metricPrefix" .Subcharts.tei }}_queue_size_sum"
      resources:
        overrides:
          namespace: {resource: "namespace"}
          service:   {resource: "service"}
    {{- end }}
{{- end }}
