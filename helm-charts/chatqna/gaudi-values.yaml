# Copyright (C) 2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

# Default values for chatqna.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: opea/chatqna:latest
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  # tag: "1.0"

port: 8888
service:
  type: ClusterIP
  port: 8888

securityContext:
  readOnlyRootFilesystem: true
  allowPrivilegeEscalation: false
  runAsNonRoot: true
  runAsUser: 1000
  capabilities:
    drop:
    - ALL
  seccompProfile:
    type: RuntimeDefault

# To override values in subchart tgi
tgi:
  LLM_MODEL_ID: Intel/neural-chat-7b-v3-3
  # LLM_MODEL_ID: /data/OpenCodeInterpreter-DS-6.7B
  image:
    repository: ghcr.io/huggingface/tgi-gaudi
    tag: "1.2.1"
  resources:
    limits:
      habana.ai/gaudi: 1

global:
  http_proxy:
  https_proxy:
  no_proxy:
  HUGGINGFACEHUB_API_TOKEN: "insert-your-huggingface-token-here"
  LANGCHAIN_TRACING_V2: false
  LANGCHAIN_API_KEY: "insert-your-langchain-key-here"
  # set modelUseHostPath to host directory if you want to use hostPath volume for model storage
  # comment out modeluseHostPath if you want to download the model from huggingface
  modelUseHostPath: /mnt/opea-models
