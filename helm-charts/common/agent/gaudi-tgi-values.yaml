# Copyright (C) 2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

# Accelerate inferencing in heaviest components to improve performance
# by overriding their subchart values

vllm:
  enabled: false

tgi:
  enabled: true
  accelDevice: "gaudi"
  image:
    repository: ghcr.io/huggingface/tgi-gaudi
    tag: "2.3.1"
  resources:
    limits:
      habana.ai/gaudi: 4
  LLM_MODEL_ID: "meta-llama/Llama-3.3-70B-Instruct"
  MAX_INPUT_LENGTH: 4096
  MAX_TOTAL_TOKENS: 8192
  CUDA_GRAPHS: ""
  OMPI_MCA_btl_vader_single_copy_mechanism: none
  PT_HPU_ENABLE_LAZY_COLLECTIVES: true
  ENABLE_HPU_GRAPH: true
  LIMIT_HPU_GRAPH: true
  USE_FLASH_ATTENTION: true
  FLASH_ATTENTION_RECOMPUTE: true
  extraCmdArgs: ["--sharded", "true", "--num-shard", "4"]
  livenessProbe:
    initialDelaySeconds: 5
    periodSeconds: 5
    timeoutSeconds: 1
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 5
    timeoutSeconds: 1
  startupProbe:
    initialDelaySeconds: 5
    periodSeconds: 5
    timeoutSeconds: 1
    failureThreshold: 120

llm_endpoint_url: http://{{ .Release.Name }}-tgi
llm_engine: tgi
