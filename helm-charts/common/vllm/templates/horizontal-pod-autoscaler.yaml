# Copyright (C) 2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

{{- if and .Values.global.monitoring .Values.autoscaling.enabled }}
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: {{ include "vllm.fullname" . }}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: {{ include "vllm.fullname" . }}
  minReplicas: 1
  maxReplicas: {{ .Values.autoscaling.maxReplicas }}
  metrics:
  - type: Object
    object:
      describedObject:
        apiVersion: v1
        # get metric for named object of given type (in same namespace)
        kind: Service
        name: {{ include "vllm.fullname" . }}
      target:
        # Metric is sum from all pods. "AverageValue" divides value returned from
        # the custom metrics API by the number of Pods before comparing to the target:
        #  https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details
        #  https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-multiple-metrics-and-custom-metrics
        type: AverageValue
{{- if .Values.accelDevice }}
        averageValue: 0.1
{{- else }}
        # allow larger latencies with unaccelerated service
        averageValue: 1.0
{{- end }}
      metric:
        name: {{ include "vllm.metricPrefix" . }}_token_latency
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 180
      policies:
      - type: Percent
        value: 25
        periodSeconds: 90
    scaleUp:
      selectPolicy: Max
      stabilizationWindowSeconds: 0
      policies:
      # Slow linear rampup in case additional CPU pods go to same node
      # (i.e. interfere with each other)
      - type: Pods
        value: 1
        periodSeconds: 90
      #- type: Percent
      #  value: 25
      #  periodSeconds: 90
{{- end }}
