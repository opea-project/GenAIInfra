{{- if and .Values.global.monitoring .Values.autoscaling.enabled }}
# Copyright (C) 2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: {{ include "vllm.fullname" . }}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: {{ include "vllm.fullname" . }}
  minReplicas: {{ .Values.autoscaling.minReplicas }}
  maxReplicas: {{ .Values.autoscaling.maxReplicas }}
  metrics:
  - type: Object
    object:
      describedObject:
        apiVersion: v1
        # get metric for named object of given type (in same namespace)
        kind: Service
        name: {{ include "vllm.fullname" . }}
      target:
        # Metric is sum from all pods. "AverageValue" divides value returned from
        # the custom metrics API by the number of Pods before comparing to the target
        # (pods need to be in Ready state faster than specified stabilization window):
        #  https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details
        #  https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-multiple-metrics-and-custom-metrics
        type: AverageValue
{{- if .Values.accelDevice }}
        averageValue: {{ .Values.autoscaling.queueSizeTarget.accel }}
{{- else }}
        averageValue: {{ .Values.autoscaling.queueSizeTarget.cpu }}
{{- end }}
      metric:
        name: {{ include "vllm.metricPrefix" . }}_queue_size_sum
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 180
      policies:
      - type: Percent
        value: 25
        periodSeconds: 90
    scaleUp:
      selectPolicy: Max
      stabilizationWindowSeconds: 0
      policies:
      # Slow linear rampup in case additional CPU pods go to same node
      # (i.e. interfere with each other)
      - type: Pods
        value: 1
        periodSeconds: 90
      #- type: Percent
      #  value: 25
      #  periodSeconds: 90
{{- end }}
