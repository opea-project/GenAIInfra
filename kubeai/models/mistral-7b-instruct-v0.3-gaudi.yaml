# Copyright (C) 2025 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

# Source: models/templates/models.yaml
apiVersion: kubeai.org/v1
kind: Model
metadata:
  name: mistral-7b-instruct-v0.3-gaudi
spec:
  features: [TextGeneration]
  url: hf://mistralai/Mistral-7B-Instruct-v0.3
  cacheProfile: default
  engine: VLLM
  args:
    - --model=mistralai/Mistral-7B-Instruct-v0.3
    - --load_format=mistral
    - --config_format=mistral
    - --tensor-parallel-size=1
    - --block-size=128
    - --max-num-seqs=512
    - --max-seq-len-to-capture=2048
    - --max-model-len=2048
    - --max-num-batched-token=2048
    - --disable-log-request
  env:
    OMPI_MCA_btl_vader_single_copy_mechanism: none
    VLLM_SKIP_WARMUP: "true"
  minReplicas: 1
  maxReplicas: 8
  # Equals to max-num-seqs (batch-size) parameter
  targetRequests: 512
  resourceProfile: gaudi-for-text-generation:1
